{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import count, col\n",
        "\n",
        "# --- 0. Setup ---\n",
        "# Initialize Spark Session (if needed, e.g., on a local machine)\n",
        "# In Azure Databricks, this step is often automatic.\n",
        "spark = SparkSession.builder.appName(\"PySparkOrderAnalysis\").getOrCreate()\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "# Load cleaned order data into PySpark (using Week 2 output) [cite: 30]\n",
        "orders_df = spark.read.csv(\"cleaned_orders.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Load customer data\n",
        "customers_df = spark.read.csv(\"customers.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# --- 2. Join and Filter ---\n",
        "# Join orders and customer tables [cite: 31]\n",
        "joined_df = orders_df.join(customers_df, \"customerid\", \"inner\")\n",
        "\n",
        "# Filter for only delayed orders (where the 'delayed' flag is 1)\n",
        "delayed_orders_df = joined_df.filter(col(\"delayed\") == 1)\n",
        "\n",
        "# --- 3. Group and Aggregate ---\n",
        "# Group by region to count delays [cite: 32]\n",
        "regional_delays_df = delayed_orders_df.groupBy(\"region\").agg(\n",
        "    count(col(\"orderid\")).alias(\"TotalDelayedOrders\")\n",
        ").sort(col(\"TotalDelayedOrders\").desc())\n",
        "\n",
        "# --- 4. Save Results (Deliverable) ---\n",
        "# Save results to a file (Output file showing delayed orders by region) [cite: 33, 35]\n",
        "output_path = \"delayed_orders_by_region_output\"\n",
        "# coalesce(1) is used to save output into a single CSV file inside the folder\n",
        "regional_delays_df.coalesce(1).write.mode(\"overwrite\").csv(\n",
        "    output_path,\n",
        "    header=True\n",
        ")\n",
        "\n",
        "# Optional: Show the result and confirmation\n",
        "print(\"--- Delayed Orders by Region ---\")\n",
        "regional_delays_df.show()\n",
        "print(f\"✅ Output file showing delayed orders by region saved to: {output_path}\")\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhE9FNBcBgFp",
        "outputId": "bcde870d-7dad-44a0-9c74-da8a6a574414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Delayed Orders by Region ---\n",
            "+------+------------------+\n",
            "|region|TotalDelayedOrders|\n",
            "+------+------------------+\n",
            "| North|                 2|\n",
            "| South|                 1|\n",
            "|  East|                 1|\n",
            "|  West|                 1|\n",
            "+------+------------------+\n",
            "\n",
            "✅ Output file showing delayed orders by region saved to: delayed_orders_by_region_output\n"
          ]
        }
      ]
    }
  ]
}