{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6947923e-062a-4f86-9e47-7495aa96a905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDD49 STEP 1 — BRONZE LAYER: RAW INGESTION\n",
    "Read raw CSV and JSON files into DataFrames and store them as Delta tables in the bronze layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "476b6d19-3e4a-44b2-b806-b6eb7bc0cf17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read raw files\n",
    "patients_df = spark.read.csv(\"/FileStore/tables/patients.csv\", header=True, inferSchema=True)\n",
    "hospitals_df = spark.read.json(\"/FileStore/tables/hospitals.json\")\n",
    "appointments_df = spark.read.csv(\"/FileStore/tables/appointments_day1.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Write as Delta tables\n",
    "patients_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze_patients\")\n",
    "hospitals_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze_hospitals\")\n",
    "appointments_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze_appointments\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fbae160-b794-4dc8-b258-c1782b32d6e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDD48 STEP 2 — SILVER LAYER: CLEANING & TRANSFORMATION\n",
    "Clean and transform the data by removing pending appointments, joining tables, and adding year/month columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7eaaa40-4eb8-4110-b75f-177faadce253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, col\n",
    "\n",
    "# Load bronze data\n",
    "patients = spark.table(\"bronze_patients\")\n",
    "hospitals = spark.table(\"bronze_hospitals\")\n",
    "appointments = spark.table(\"bronze_appointments\")\n",
    "\n",
    "# Filter out pending\n",
    "appointments_filtered = appointments.filter(appointments.status != \"Pending\")\n",
    "\n",
    "# Rename duplicate column before join\n",
    "patients = patients.withColumnRenamed(\"region\", \"patient_region\")\n",
    "hospitals = hospitals.withColumnRenamed(\"region\", \"hospital_region\")\n",
    "\n",
    "# Join + Add Year/Month\n",
    "silver_df = (appointments_filtered\n",
    "    .join(patients, \"patient_id\", \"left\")\n",
    "    .join(hospitals, \"hospital_id\", \"left\")\n",
    "    .withColumn(\"year\", year(col(\"appointment_date\")))\n",
    "    .withColumn(\"month\", month(col(\"appointment_date\")))\n",
    ")\n",
    "\n",
    "# Save\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_appointments\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "331061e0-7ed4-44e9-8553-2b893213f87a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDD47 STEP 3 — GOLD LAYER: ANALYTICAL AGGREGATIONS\n",
    "Create analytical summary tables for revenue, patient counts, and top diagnoses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db3f77f0-cedb-46b2-bf0c-0ddd14386b31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, count, desc\n",
    "\n",
    "# Load silver table\n",
    "silver = spark.table(\"silver_appointments\")\n",
    "\n",
    "# Total revenue per hospital\n",
    "revenue_per_hospital = silver.groupBy(\"hospital_name\") \\\n",
    "    .agg(sum(\"cost\").alias(\"total_revenue\"))\n",
    "\n",
    "# Total patients per region (using patient_region)\n",
    "patients_per_region = silver.groupBy(\"patient_region\") \\\n",
    "    .agg(count(\"patient_id\").alias(\"total_patients\"))\n",
    "\n",
    "# Top 3 diagnoses by total cost\n",
    "top3_diagnosis = silver.groupBy(\"diagnosis\") \\\n",
    "    .agg(sum(\"cost\").alias(\"total_cost\")) \\\n",
    "    .orderBy(desc(\"total_cost\")) \\\n",
    "    .limit(3)\n",
    "\n",
    "# Save all gold tables separately\n",
    "revenue_per_hospital.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_revenue_per_hospital\")\n",
    "patients_per_region.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_patients_per_region\")\n",
    "top3_diagnosis.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_top3_diagnosis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81fc8259-d1b0-49d8-9c14-9c93db89bc35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83D\uDD01 STEP 4 — INCREMENTAL LOAD SIMULATION\n",
    "Load new appointment data (Day 2), filter out pending records, and upsert into the silver table using Delta MERGE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e122c5b7-c1df-4fcb-8613-81f0f3a4cae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Read new file\n",
    "new_appointments = spark.read.csv(\n",
    "    \"/FileStore/tables/appointments_day2.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "# Filter out Pending records (if any)\n",
    "new_appointments_filtered = new_appointments.filter(\n",
    "    new_appointments.status != \"Pending\"\n",
    ")\n",
    "\n",
    "# Load silver Delta table\n",
    "silver_table = DeltaTable.forName(spark, \"silver_appointments\")\n",
    "\n",
    "# Define column mapping\n",
    "update_dict = {\n",
    "    \"appointment_id\": \"source.appointment_id\",\n",
    "    \"patient_id\": \"source.patient_id\",\n",
    "    \"hospital_id\": \"source.hospital_id\",\n",
    "    \"appointment_date\": \"source.appointment_date\",\n",
    "    \"diagnosis\": \"source.diagnosis\",\n",
    "    \"cost\": \"source.cost\",\n",
    "    \"status\": \"source.status\"\n",
    "}\n",
    "\n",
    "# Upsert new data\n",
    "silver_table.alias(\"target\").merge(\n",
    "    new_appointments_filtered.alias(\"source\"),\n",
    "    \"target.appointment_id = source.appointment_id\"\n",
    ").whenMatchedUpdate(\n",
    "    set=update_dict\n",
    ").whenNotMatchedInsert(\n",
    "    values=update_dict\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e00a8c28-d380-44a5-ba8a-523df6ce3a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ✅ STEP 5 — VERIFY INCREMENTAL CHANGES\n",
    "Check if new data was merged successfully by counting rows and recalculating total revenue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "971bbf02-8afc-48ef-a234-881aa01ef143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after incremental load: 6\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>hospital_name</th><th>total_revenue</th></tr></thead><tbody><tr><td>City Care</td><td>400</td></tr><tr><td>CureWell</td><td>300</td></tr><tr><td>LifePlus</td><td>250</td></tr><tr><td>null</td><td>1850</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "City Care",
         400
        ],
        [
         "CureWell",
         300
        ],
        [
         "LifePlus",
         250
        ],
        [
         null,
         1850
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "hospital_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reload updated silver table\n",
    "silver_updated = spark.table(\"silver_appointments\")\n",
    "\n",
    "# Check total rows after merge\n",
    "print(\"Total rows after incremental load:\", silver_updated.count())\n",
    "\n",
    "# Recalculate revenue to see the difference\n",
    "updated_revenue = silver_updated.groupBy(\"hospital_name\").agg(sum(\"cost\").alias(\"total_revenue\"))\n",
    "display(updated_revenue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "546d7ad9-d1e2-4e5d-839d-2af66917f04a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83D\uDD52 STEP 6 — DELTA LAKE FEATURES\n",
    "Explore key Delta Lake capabilities: Time Travel, Vacuum, and Optimize with Z-Ordering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a6b0497-2cac-4878-aa7a-af84f115dc82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>hospital_name</th><th>total_revenue</th></tr></thead><tbody><tr><td>City Care</td><td>400</td></tr><tr><td>CureWell</td><td>300</td></tr><tr><td>LifePlus</td><td>250</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "City Care",
         400
        ],
        [
         "CureWell",
         300
        ],
        [
         "LifePlus",
         250
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "hospital_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,recompressionCodec:string,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,isFull:boolean,approxClusteringQuality:double,approxClusteringQualityPerColumn:array<double>,approxClusteringCoverage:double,compactionType:string,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numIdealFilesWithTrimmedStringMaxValue:bigint,numAddedFilesWithSameMinMaxOnClusteringColumns:array<bigint>,numClusteringTasksPlanned:int,numClusteringTasksNotPlannedDueToPO:int,numCompactionTasksPlanned:int,numCompactionTasksPlannedUndoneDueToPO:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numLeafNodesCompactedUndoneDueToPO:bigint,numIntermediateNodesCompacted:bigint,numIntermediateNodesCompactedUndoneDueToPO:bigint,totalSizeOfDataToCompactInBytes:bigint,totalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Travel: view gold table before incremental load\n",
    "display(\n",
    "    spark.sql(\n",
    "        \"SELECT * FROM gold_revenue_per_hospital VERSION AS OF 0\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Vacuum: clean up old versions (recommended minimum is 168 hours)\n",
    "spark.sql(\n",
    "    \"VACUUM gold_revenue_per_hospital RETAIN 168 HOURS\"\n",
    ")\n",
    "\n",
    "# Optimize + Z-ORDER\n",
    "spark.sql(\n",
    "    \"OPTIMIZE gold_revenue_per_hospital ZORDER BY (hospital_name)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88032136-bc42-4b89-8ec5-a372e08dec9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83D\uDCCA STEP 7 — ANALYTICAL QUESTIONS\n",
    "Answer key business questions using SQL queries on the Silver table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caa39062-4308-4fe6-8e41-56e5e748a722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n|hospital_name|total_revenue|\n+-------------+-------------+\n|    City Care|          400|\n|     CureWell|          300|\n|     LifePlus|          250|\n|         NULL|         1850|\n+-------------+-------------+\n\n+-------------+--------+\n|    diagnosis|avg_cost|\n+-------------+--------+\n|          Flu|   250.0|\n|     Diabetes|   425.0|\n|      Allergy|   300.0|\n|Heart Disease|  1200.0|\n|         Cold|   200.0|\n+-------------+--------+\n\n+--------------+--------------+\n|patient_region|total_patients|\n+--------------+--------------+\n|          NULL|             3|\n|          West|             1|\n|         North|             1|\n|         South|             1|\n+--------------+--------------+\n\n+----+-----+------------------+\n|year|month|total_appointments|\n+----+-----+------------------+\n|NULL| NULL|                 3|\n|2024|    1|                 3|\n+----+-----+------------------+\n\n+-------------+----------+\n|    diagnosis|total_cost|\n+-------------+----------+\n|Heart Disease|      1200|\n|     Diabetes|       850|\n|      Allergy|       300|\n|          Flu|       250|\n|         Cold|       200|\n+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "#  Total revenue generated by each hospital\n",
    "spark.sql(\"SELECT hospital_name, SUM(cost) AS total_revenue FROM silver_appointments GROUP BY hospital_name\").show()\n",
    "\n",
    "#  Average cost per diagnosis\n",
    "spark.sql(\"SELECT diagnosis, AVG(cost) AS avg_cost FROM silver_appointments GROUP BY diagnosis\").show()\n",
    "\n",
    "#  Number of patients served per region\n",
    "spark.sql(\"SELECT patient_region, COUNT(DISTINCT patient_id) AS total_patients FROM silver_appointments GROUP BY patient_region\").show()\n",
    "\n",
    "#  Trend of appointments month-over-month\n",
    "spark.sql(\"SELECT year, month, COUNT(appointment_id) AS total_appointments FROM silver_appointments GROUP BY year, month ORDER BY year, month\").show()\n",
    "\n",
    "#  Top 5 most expensive treatments (last 6 months)\n",
    "spark.sql(\"SELECT diagnosis, SUM(cost) AS total_cost FROM silver_appointments GROUP BY diagnosis ORDER BY total_cost DESC LIMIT 5\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Healthcare Data Engineering Platform on Azure Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}